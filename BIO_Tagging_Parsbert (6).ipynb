{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K2BIUo1obI2S"
      },
      "source": [
        "# Install Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZNGrS5KeDblz",
        "outputId": "6440355d-3d01-495a-b7da-3bb45e0769c7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MemTotal:       13290460 kB\n",
            "MemAvailable:   11948904 kB\n"
          ]
        }
      ],
      "source": [
        "!cat /proc/meminfo | grep MemTotal\n",
        "!cat /proc/meminfo | grep MemAvailable"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i2iNICuuHT7l",
        "outputId": "b1bed8ee-670b-4a40-af0e-31cf734a7c4d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.44.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.15.4)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.24.6)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.5.15)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.4)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.5)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.6.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.8)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n",
            "Requirement already satisfied: tf_keras in /usr/local/lib/python3.10/dist-packages (2.17.0)\n",
            "Requirement already satisfied: tensorflow<2.18,>=2.17 in /usr/local/lib/python3.10/dist-packages (from tf_keras) (2.17.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17->tf_keras) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17->tf_keras) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17->tf_keras) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17->tf_keras) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17->tf_keras) (0.2.0)\n",
            "Requirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17->tf_keras) (3.11.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17->tf_keras) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17->tf_keras) (0.4.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17->tf_keras) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17->tf_keras) (24.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17->tf_keras) (3.20.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17->tf_keras) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17->tf_keras) (71.0.4)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17->tf_keras) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17->tf_keras) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17->tf_keras) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17->tf_keras) (1.16.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17->tf_keras) (1.64.1)\n",
            "Requirement already satisfied: tensorboard<2.18,>=2.17 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17->tf_keras) (2.17.0)\n",
            "Requirement already satisfied: keras>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17->tf_keras) (3.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17->tf_keras) (0.37.1)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17->tf_keras) (1.26.4)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow<2.18,>=2.17->tf_keras) (0.44.0)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow<2.18,>=2.17->tf_keras) (13.8.0)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow<2.18,>=2.17->tf_keras) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow<2.18,>=2.17->tf_keras) (0.12.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow<2.18,>=2.17->tf_keras) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow<2.18,>=2.17->tf_keras) (3.8)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow<2.18,>=2.17->tf_keras) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow<2.18,>=2.17->tf_keras) (2024.8.30)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow<2.18,>=2.17->tf_keras) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow<2.18,>=2.17->tf_keras) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow<2.18,>=2.17->tf_keras) (3.0.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow<2.18,>=2.17->tf_keras) (2.1.5)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow<2.18,>=2.17->tf_keras) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow<2.18,>=2.17->tf_keras) (2.16.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow<2.18,>=2.17->tf_keras) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade transformers\n",
        "!pip install --upgrade tf_keras\n",
        "# then restrat session"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A4Am7dtWbDdg"
      },
      "source": [
        "# part 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3CBJBcT8Dl6K",
        "outputId": "404c6651-edc6-47d2-a8ef-969241c19858"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MemTotal:       13290460 kB\n",
            "MemAvailable:   12147388 kB\n"
          ]
        }
      ],
      "source": [
        "!cat /proc/meminfo | grep MemTotal\n",
        "!cat /proc/meminfo | grep MemAvailable"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pliQHwJ7HeAb"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ['TF_USE_LEGACY_KERAS'] = '1'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ikw91M6snIz0"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv('dataset2_2.csv', delimiter='\\t', header=None, names=['Sentence', 'Tags', 'Intent'])"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fmRd0dluuUPI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "referenced_widgets": [
            "9c64a69d4ddf4265802916c450032987",
            "0d62faa6e86f4b198e2886cd884a6601"
          ]
        },
        "id": "JccGeo1-nXUQ",
        "outputId": "99e573f5-5b98-464b-c64a-277b14158e65"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9c64a69d4ddf4265802916c450032987",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/1.20M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0d62faa6e86f4b198e2886cd884a6601",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/440 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "from transformers import BertTokenizer\n",
        "\n",
        "model_name = \"HooshvareLab/bert-fa-base-uncased\"  # ParsBERT model\n",
        "tokenizer = BertTokenizer.from_pretrained(model_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AqaqClQCnk4-"
      },
      "outputs": [],
      "source": [
        "# Encode sentences and tags\n",
        "input_ids = []\n",
        "attention_masks = []\n",
        "tag_ids = []\n",
        "\n",
        "# Creating tag encoders\n",
        "tag2id = {tag: idx for idx, tag in enumerate(sorted(set(tag for tags in df['Tags'] for tag in tags.split())))}\n",
        "id2tag = {idx: tag for tag, idx in tag2id.items()}\n",
        "padding_tag_value = len(tag2id)\n",
        "tag2id['PAD'] = padding_tag_value\n",
        "id2tag[padding_tag_value] = 'PAD'\n",
        "\n",
        "for i, row in df.iterrows():\n",
        "    sentence = row['Sentence']\n",
        "    tags = row['Tags'].split()\n",
        "\n",
        "    # Tokenize sentence using BERT tokenizer\n",
        "    bert_tokens = tokenizer.tokenize(sentence)\n",
        "    input_id = tokenizer.convert_tokens_to_ids(bert_tokens)\n",
        "    tag_id = [tag2id[tag] for tag in tags]\n",
        "\n",
        "    input_ids.append(input_id)\n",
        "    tag_ids.append(tag_id)\n",
        "    attention_masks.append([1] * len(input_id))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "easYvhptnl0B",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "outputId": "32ebf06f-2281-4244-db8a-a10632b89d9e"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'input_ids' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-2b265be1f74a>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msequence\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpad_sequences\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mMAX_LEN\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0minput_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpad_sequences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxlen\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mMAX_LEN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"long\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"post\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtruncating\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"post\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mtag_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpad_sequences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtag_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxlen\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mMAX_LEN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"long\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"post\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtruncating\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"post\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpadding_tag_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mattention_masks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpad_sequences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattention_masks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxlen\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mMAX_LEN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"long\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"post\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtruncating\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"post\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'input_ids' is not defined"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "MAX_LEN = 128\n",
        "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", padding=\"post\", truncating=\"post\")\n",
        "tag_ids = pad_sequences(tag_ids, maxlen=MAX_LEN, dtype=\"long\", padding=\"post\", truncating=\"post\", value=padding_tag_value)\n",
        "attention_masks = pad_sequences(attention_masks, maxlen=MAX_LEN, dtype=\"long\", padding=\"post\", truncating=\"post\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vhux8JPhnqgi"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "# Convert to numpy arrays\n",
        "input_ids = np.array(input_ids)\n",
        "tag_ids = np.array(tag_ids)\n",
        "attention_masks = np.array(attention_masks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lijuEhzYnsM4"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test, mask_train, mask_test = train_test_split(input_ids, tag_ids, attention_masks, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "referenced_widgets": [
            "4cb9dacb17e24bb19d7ed5a6a09c02c0"
          ]
        },
        "id": "Wdw_owG2nu73",
        "outputId": "e5ab4b2a-1d6e-4ed6-9cfd-fd797bc40a57"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4cb9dacb17e24bb19d7ed5a6a09c02c0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tf_model.h5:   0%|          | 0.00/963M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "All model checkpoint layers were used when initializing TFBertForTokenClassification.\n",
            "\n",
            "Some layers of TFBertForTokenClassification were not initialized from the model checkpoint at HooshvareLab/bert-fa-base-uncased and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "from transformers import TFBertForTokenClassification\n",
        "\n",
        "model = TFBertForTokenClassification.from_pretrained(model_name, num_labels=len(tag2id) + 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1HV85DUbN7-a",
        "outputId": "3cfc2843-0d09-436b-e730-284c601b50f1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Datasets prepared successfully!\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Create TensorFlow datasets\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((\n",
        "    {'input_ids': X_train, 'attention_mask': mask_train},\n",
        "    y_train\n",
        "))\n",
        "\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((\n",
        "    {'input_ids': X_test, 'attention_mask': mask_test},\n",
        "    y_test\n",
        "))\n",
        "\n",
        "# Batch the datasets\n",
        "train_dataset = train_dataset.shuffle(len(X_train)).batch(16)\n",
        "test_dataset = test_dataset.batch(16)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mAX-yuYvnyQ4"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "adam_optimizer = Adam(learning_rate=3e-5)\n",
        "\n",
        "model.compile(optimizer=adam_optimizer,\n",
        "              metrics=['accuracy'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MEaOQf-Inywl",
        "outputId": "abd26b6a-88c0-40be-ec53-b8937f0e4caa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "675/675 [==============================] - 343s 443ms/step - loss: 0.0988 - accuracy: 0.9841 - val_loss: 0.0124 - val_accuracy: 0.9978\n",
            "Epoch 2/3\n",
            "675/675 [==============================] - 303s 449ms/step - loss: 0.0083 - accuracy: 0.9989 - val_loss: 0.0026 - val_accuracy: 0.9996\n",
            "Epoch 3/3\n",
            "675/675 [==============================] - 303s 449ms/step - loss: 0.0028 - accuracy: 0.9997 - val_loss: 0.0013 - val_accuracy: 0.9998\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(train_dataset, validation_data=test_dataset, epochs=3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZRBAynlSn0qb",
        "outputId": "2ed13d98-1afc-4d5f-fd8d-7557fbfa49c7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "('ParsBERT_BIO_Tagging_Tokenizer/tokenizer_config.json',\n",
              " 'ParsBERT_BIO_Tagging_Tokenizer/special_tokens_map.json',\n",
              " 'ParsBERT_BIO_Tagging_Tokenizer/vocab.txt',\n",
              " 'ParsBERT_BIO_Tagging_Tokenizer/added_tokens.json')"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Save the model\n",
        "model.save_pretrained(\"ParsBERT_BIO_Tagging_Model\")\n",
        "tokenizer.save_pretrained(\"ParsBERT_BIO_Tagging_Tokenizer\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bRM8Ma9Yn2Pl",
        "outputId": "6eb7178c-075b-470e-a799-bbf063daebad"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "169/169 [==============================] - 33s 145ms/step\n",
            "Classification Report:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                        precision    recall  f1-score   support\n",
            "\n",
            "              B-5G_yes       1.00      1.00      1.00       144\n",
            "          B-5G_yes_not       0.44      1.00      0.62         4\n",
            "                 B-RAM       1.00      1.00      1.00        58\n",
            "                B-RAM1       0.98      1.00      0.99        56\n",
            "            B-RAM1_not       1.00      0.50      0.67         2\n",
            "                B-RAM2       0.95      1.00      0.97        53\n",
            "            B-RAM2_not       0.00      0.00      0.00         4\n",
            "                B-RAM3       1.00      1.00      1.00        45\n",
            "            B-RAM3_not       1.00      1.00      1.00         4\n",
            "             B-RAM_not       0.00      0.00      0.00         2\n",
            "             B-RAMless       1.00      1.00      1.00        59\n",
            "             B-RAMmore       0.97      1.00      0.99        68\n",
            "    B-appearanceScore1       1.00      1.00      1.00       246\n",
            "B-appearanceScore1_not       0.70      1.00      0.82         7\n",
            "            B-batteryC       1.00      1.00      1.00        65\n",
            "           B-batteryC1       1.00      0.98      0.99        50\n",
            "       B-batteryC1_not       0.00      0.00      0.00         2\n",
            "           B-batteryC2       1.00      1.00      1.00        45\n",
            "       B-batteryC2_not       0.75      1.00      0.86         3\n",
            "           B-batteryC3       1.00      1.00      1.00        47\n",
            "       B-batteryC3_not       1.00      1.00      1.00         1\n",
            "        B-batteryC_not       0.00      0.00      0.00         1\n",
            "        B-batteryCless       1.00      1.00      1.00        69\n",
            "        B-batteryCmore       1.00      1.00      1.00        58\n",
            "        B-batteryLife1       1.00      1.00      1.00        81\n",
            "    B-batteryLife1_not       1.00      1.00      1.00         1\n",
            "        B-batteryLife2       1.00      1.00      1.00        79\n",
            "    B-batteryLife2_not       1.00      1.00      1.00         4\n",
            "        B-batteryLife3       1.00      1.00      1.00        72\n",
            "    B-batteryLife3_not       1.00      1.00      1.00         2\n",
            "               B-brand       1.00      1.00      1.00       112\n",
            "              B-brand1       0.99      1.00      0.99        69\n",
            "          B-brand1_not       0.00      0.00      0.00         1\n",
            "              B-brand2       1.00      1.00      1.00        81\n",
            "          B-brand2_not       1.00      1.00      1.00         4\n",
            "           B-brand_not       1.00      1.00      1.00        98\n",
            "       B-chipsetScore1       1.00      1.00      1.00       109\n",
            "   B-chipsetScore1_not       0.86      1.00      0.92         6\n",
            "       B-chipsetScore2       1.00      1.00      1.00       116\n",
            "   B-chipsetScore2_not       0.40      1.00      0.57         2\n",
            "               B-color       1.00      1.00      1.00        96\n",
            "              B-color1       0.96      1.00      0.98        74\n",
            "          B-color1_not       0.00      0.00      0.00         3\n",
            "              B-color2       0.99      1.00      0.99        75\n",
            "          B-color2_not       0.00      0.00      0.00         2\n",
            "           B-color_not       1.00      1.00      1.00        96\n",
            "         B-displaySize       1.00      1.00      1.00        55\n",
            "        B-displaySize1       1.00      1.00      1.00        53\n",
            "    B-displaySize1_not       1.00      1.00      1.00         2\n",
            "        B-displaySize2       0.96      1.00      0.98        72\n",
            "    B-displaySize2_not       0.00      0.00      0.00         3\n",
            "        B-displaySize3       0.95      1.00      0.98        40\n",
            "    B-displaySize3_not       1.00      0.33      0.50         3\n",
            "     B-displaySize_not       0.00      0.00      0.00         2\n",
            "     B-displaySizeless       1.00      1.00      1.00        54\n",
            "     B-displaySizemore       1.00      1.00      1.00        53\n",
            "      B-fastCharge_yes       1.00      1.00      1.00       148\n",
            "  B-fastCharge_yes_not       1.00      1.00      1.00         3\n",
            "         B-intermemory       1.00      1.00      1.00        62\n",
            "        B-intermemory1       0.96      1.00      0.98        50\n",
            "    B-intermemory1_not       0.00      0.00      0.00         2\n",
            "        B-intermemory2       1.00      1.00      1.00        52\n",
            "    B-intermemory2_not       1.00      1.00      1.00         1\n",
            "        B-intermemory3       0.93      1.00      0.96        50\n",
            "    B-intermemory3_not       0.00      0.00      0.00         4\n",
            "     B-intermemory_not       1.00      1.00      1.00         2\n",
            "     B-intermemoryless       0.99      1.00      0.99        72\n",
            " B-intermemoryless_not       0.00      0.00      0.00         1\n",
            "     B-intermemorymore       0.97      1.00      0.99        73\n",
            " B-intermemorymore_not       0.00      0.00      0.00         3\n",
            "              B-madeIn       1.00      0.99      1.00       275\n",
            "          B-madeIn_not       1.00      1.00      1.00        10\n",
            "          B-maincamera       1.00      1.00      1.00        61\n",
            "         B-maincamera1       1.00      1.00      1.00        63\n",
            "     B-maincamera1_not       0.00      0.00      0.00         1\n",
            "         B-maincamera2       0.97      1.00      0.98        58\n",
            "     B-maincamera2_not       0.00      0.00      0.00         2\n",
            "         B-maincamera3       0.96      1.00      0.98        47\n",
            "     B-maincamera3_not       0.00      0.00      0.00         3\n",
            "      B-maincameraless       1.00      1.00      1.00        63\n",
            "      B-maincameramore       1.00      1.00      1.00        60\n",
            "      B-memorycard_yes       1.00      1.00      1.00       116\n",
            "  B-memorycard_yes_not       1.00      1.00      1.00         5\n",
            "                B-nsim       1.00      1.00      1.00       239\n",
            "            B-nsim_not       1.00      1.00      1.00         5\n",
            "                  B-os       1.00      1.00      1.00       106\n",
            "              B-os_not       1.00      1.00      1.00       141\n",
            "             B-pen_yes       1.00      1.00      1.00       187\n",
            "         B-pen_yes_not       1.00      1.00      1.00         5\n",
            "               B-price       1.00      1.00      1.00        60\n",
            "              B-price1       0.96      1.00      0.98        51\n",
            "          B-price1_not       0.00      0.00      0.00         2\n",
            "              B-price2       1.00      1.00      1.00        53\n",
            "          B-price2_not       1.00      1.00      1.00         1\n",
            "              B-price3       0.98      0.98      0.98        43\n",
            "          B-price3_not       0.00      0.00      0.00         2\n",
            "           B-price_not       0.00      0.00      0.00         1\n",
            "           B-priceless       1.00      1.00      1.00        44\n",
            "           B-pricemore       1.00      1.00      1.00        62\n",
            "       B-pricemore_not       0.00      0.00      0.00         2\n",
            "         B-selficamera       1.00      1.00      1.00        56\n",
            "        B-selficamera1       0.98      1.00      0.99        60\n",
            "    B-selficamera1_not       0.00      0.00      0.00         3\n",
            "        B-selficamera2       1.00      1.00      1.00        45\n",
            "    B-selficamera2_not       1.00      1.00      1.00         1\n",
            "        B-selficamera3       1.00      1.00      1.00        60\n",
            "    B-selficamera3_not       1.00      1.00      1.00         1\n",
            "     B-selficameraless       0.98      1.00      0.99        86\n",
            " B-selficameraless_not       0.00      0.00      0.00         2\n",
            "     B-selficameramore       1.00      1.00      1.00        53\n",
            " B-selficameramore_not       0.00      0.00      0.00         1\n",
            "              B-weight       1.00      1.00      1.00        62\n",
            "             B-weight1       1.00      1.00      1.00        63\n",
            "             B-weight2       0.94      1.00      0.97        64\n",
            "         B-weight2_not       0.00      0.00      0.00         4\n",
            "             B-weight3       0.97      1.00      0.98        59\n",
            "         B-weight3_not       0.67      0.67      0.67         3\n",
            "          B-weight_not       0.00      0.00      0.00         1\n",
            "          B-weightless       1.00      1.00      1.00        51\n",
            "      B-weightless_not       0.00      0.00      0.00         0\n",
            "          B-weightmore       1.00      1.00      1.00        64\n",
            "              I-5G_yes       0.98      1.00      0.99        50\n",
            "          I-5G_yes_not       0.00      0.00      0.00         1\n",
            "                I-RAM1       1.00      1.00      1.00        20\n",
            "                I-RAM2       0.75      1.00      0.86         9\n",
            "            I-RAM2_not       0.00      0.00      0.00         3\n",
            "                I-RAM3       1.00      1.00      1.00         5\n",
            "           I-batteryC1       1.00      1.00      1.00        17\n",
            "           I-batteryC2       1.00      1.00      1.00         9\n",
            "           I-batteryC3       1.00      1.00      1.00         3\n",
            "              I-brand1       1.00      1.00      1.00         5\n",
            "               I-color       1.00      1.00      1.00         9\n",
            "              I-color2       1.00      1.00      1.00        30\n",
            "           I-color_not       1.00      1.00      1.00        10\n",
            "      I-fastCharge_yes       1.00      1.00      1.00       148\n",
            "  I-fastCharge_yes_not       1.00      1.00      1.00         3\n",
            "        I-intermemory1       1.00      1.00      1.00        20\n",
            "        I-intermemory2       0.91      1.00      0.95        10\n",
            "    I-intermemory2_not       0.00      0.00      0.00         1\n",
            "        I-intermemory3       1.00      1.00      1.00         3\n",
            "         I-maincamera1       1.00      1.00      1.00        29\n",
            "         I-maincamera2       1.00      1.00      1.00        11\n",
            "         I-maincamera3       0.88      1.00      0.93         7\n",
            "     I-maincamera3_not       0.00      0.00      0.00         1\n",
            "      I-memorycard_yes       1.00      1.00      1.00       116\n",
            "  I-memorycard_yes_not       1.00      1.00      1.00         5\n",
            "               I-price       1.00      1.00      1.00        60\n",
            "              I-price1       0.95      1.00      0.97        18\n",
            "              I-price2       1.00      1.00      1.00        18\n",
            "              I-price3       1.00      1.00      1.00         7\n",
            "           I-price_not       0.00      0.00      0.00         1\n",
            "           I-priceless       1.00      1.00      1.00        44\n",
            "           I-pricemore       0.97      1.00      0.98        62\n",
            "       I-pricemore_not       0.00      0.00      0.00         2\n",
            "        I-selficamera1       0.94      1.00      0.97        17\n",
            "    I-selficamera1_not       0.00      0.00      0.00         1\n",
            "        I-selficamera2       1.00      1.00      1.00        16\n",
            "        I-selficamera3       1.00      1.00      1.00        12\n",
            "             I-weight1       1.00      1.00      1.00        17\n",
            "                     O       1.00      1.00      1.00     39276\n",
            "\n",
            "              accuracy                           1.00     45719\n",
            "             macro avg       0.77      0.78      0.77     45719\n",
            "          weighted avg       1.00      1.00      1.00     45719\n",
            "\n",
            "Overall Accuracy: 0.9984\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred_prob = model.predict(test_dataset)\n",
        "y_pred_indices = np.argmax(y_pred_prob.logits, axis=-1)\n",
        "\n",
        "# Convert predictions and true labels to 1D arrays\n",
        "y_pred_indices = y_pred_indices.reshape(-1)\n",
        "y_test_flat = y_test.reshape(-1)\n",
        "\n",
        "# Create mask to remove padding\n",
        "mask = (y_test_flat != padding_tag_value)\n",
        "y_pred_filtered = y_pred_indices[mask]\n",
        "y_true_filtered = y_test_flat[mask]\n",
        "\n",
        "# Map indices to tags\n",
        "id2tag = {idx: tag for tag, idx in tag2id.items()}\n",
        "y_pred_tags = [id2tag.get(index, 'OOV') for index in y_pred_filtered]\n",
        "y_true_tags = [id2tag.get(index, 'OOV') for index in y_true_filtered]\n",
        "\n",
        "# Find unique labels in predictions and true labels\n",
        "unique_labels = set(y_true_tags + y_pred_tags)\n",
        "\n",
        "# Define labels and target names\n",
        "labels = sorted(unique_labels)\n",
        "\n",
        "# Print classification report\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_true_tags, y_pred_tags, labels=labels, target_names=labels))\n",
        "\n",
        "# Print accuracy\n",
        "accuracy = accuracy_score(y_true_tags, y_pred_tags)\n",
        "print(f\"Overall Accuracy: {accuracy:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JPJmrjt8D7MM",
        "outputId": "92b8bc37-891a-44a7-a15b-83f4c10153d4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MemTotal:       13290460 kB\n",
            "MemAvailable:    8887920 kB\n"
          ]
        }
      ],
      "source": [
        "!cat /proc/meminfo | grep MemTotal\n",
        "!cat /proc/meminfo | grep MemAvailable"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sc_0GbznIQGm",
        "outputId": "27b05d10-f5f8-428c-fba1-9d0de98942dd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'B-5G_yes': 0,\n",
              " 'B-5G_yes_not': 1,\n",
              " 'B-RAM': 2,\n",
              " 'B-RAM1': 3,\n",
              " 'B-RAM1_not': 4,\n",
              " 'B-RAM2': 5,\n",
              " 'B-RAM2_not': 6,\n",
              " 'B-RAM3': 7,\n",
              " 'B-RAM3_not': 8,\n",
              " 'B-RAM_not': 9,\n",
              " 'B-RAMless': 10,\n",
              " 'B-RAMless_not': 11,\n",
              " 'B-RAMmore': 12,\n",
              " 'B-RAMmore_not': 13,\n",
              " 'B-appearanceScore1': 14,\n",
              " 'B-appearanceScore1_not': 15,\n",
              " 'B-batteryC': 16,\n",
              " 'B-batteryC1': 17,\n",
              " 'B-batteryC1_not': 18,\n",
              " 'B-batteryC2': 19,\n",
              " 'B-batteryC2_not': 20,\n",
              " 'B-batteryC3': 21,\n",
              " 'B-batteryC3_not': 22,\n",
              " 'B-batteryC_not': 23,\n",
              " 'B-batteryCless': 24,\n",
              " 'B-batteryCless_not': 25,\n",
              " 'B-batteryCmore': 26,\n",
              " 'B-batteryCmore_not': 27,\n",
              " 'B-batteryLife1': 28,\n",
              " 'B-batteryLife1_not': 29,\n",
              " 'B-batteryLife2': 30,\n",
              " 'B-batteryLife2_not': 31,\n",
              " 'B-batteryLife3': 32,\n",
              " 'B-batteryLife3_not': 33,\n",
              " 'B-brand': 34,\n",
              " 'B-brand1': 35,\n",
              " 'B-brand1_not': 36,\n",
              " 'B-brand2': 37,\n",
              " 'B-brand2_not': 38,\n",
              " 'B-brand_not': 39,\n",
              " 'B-chipsetScore1': 40,\n",
              " 'B-chipsetScore1_not': 41,\n",
              " 'B-chipsetScore2': 42,\n",
              " 'B-chipsetScore2_not': 43,\n",
              " 'B-color': 44,\n",
              " 'B-color1': 45,\n",
              " 'B-color1_not': 46,\n",
              " 'B-color2': 47,\n",
              " 'B-color2_not': 48,\n",
              " 'B-color_not': 49,\n",
              " 'B-displaySize': 50,\n",
              " 'B-displaySize1': 51,\n",
              " 'B-displaySize1_not': 52,\n",
              " 'B-displaySize2': 53,\n",
              " 'B-displaySize2_not': 54,\n",
              " 'B-displaySize3': 55,\n",
              " 'B-displaySize3_not': 56,\n",
              " 'B-displaySize_not': 57,\n",
              " 'B-displaySizeless': 58,\n",
              " 'B-displaySizeless_not': 59,\n",
              " 'B-displaySizemore': 60,\n",
              " 'B-displaySizemore_not': 61,\n",
              " 'B-fastCharge_yes': 62,\n",
              " 'B-fastCharge_yes_not': 63,\n",
              " 'B-intermemory': 64,\n",
              " 'B-intermemory1': 65,\n",
              " 'B-intermemory1_not': 66,\n",
              " 'B-intermemory2': 67,\n",
              " 'B-intermemory2_not': 68,\n",
              " 'B-intermemory3': 69,\n",
              " 'B-intermemory3_not': 70,\n",
              " 'B-intermemory_not': 71,\n",
              " 'B-intermemoryless': 72,\n",
              " 'B-intermemoryless_not': 73,\n",
              " 'B-intermemorymore': 74,\n",
              " 'B-intermemorymore_not': 75,\n",
              " 'B-madeIn': 76,\n",
              " 'B-madeIn_not': 77,\n",
              " 'B-maincamera': 78,\n",
              " 'B-maincamera1': 79,\n",
              " 'B-maincamera1_not': 80,\n",
              " 'B-maincamera2': 81,\n",
              " 'B-maincamera2_not': 82,\n",
              " 'B-maincamera3': 83,\n",
              " 'B-maincamera3_not': 84,\n",
              " 'B-maincamera_not': 85,\n",
              " 'B-maincameraless': 86,\n",
              " 'B-maincameraless_not': 87,\n",
              " 'B-maincameramore': 88,\n",
              " 'B-maincameramore_not': 89,\n",
              " 'B-memorycard_yes': 90,\n",
              " 'B-memorycard_yes_not': 91,\n",
              " 'B-nsim': 92,\n",
              " 'B-nsim_not': 93,\n",
              " 'B-os': 94,\n",
              " 'B-os_not': 95,\n",
              " 'B-pen_yes': 96,\n",
              " 'B-pen_yes_not': 97,\n",
              " 'B-price': 98,\n",
              " 'B-price1': 99,\n",
              " 'B-price1_not': 100,\n",
              " 'B-price2': 101,\n",
              " 'B-price2_not': 102,\n",
              " 'B-price3': 103,\n",
              " 'B-price3_not': 104,\n",
              " 'B-price_not': 105,\n",
              " 'B-priceless': 106,\n",
              " 'B-priceless_not': 107,\n",
              " 'B-pricemore': 108,\n",
              " 'B-pricemore_not': 109,\n",
              " 'B-selficamera': 110,\n",
              " 'B-selficamera1': 111,\n",
              " 'B-selficamera1_not': 112,\n",
              " 'B-selficamera2': 113,\n",
              " 'B-selficamera2_not': 114,\n",
              " 'B-selficamera3': 115,\n",
              " 'B-selficamera3_not': 116,\n",
              " 'B-selficamera_not': 117,\n",
              " 'B-selficameraless': 118,\n",
              " 'B-selficameraless_not': 119,\n",
              " 'B-selficameramore': 120,\n",
              " 'B-selficameramore_not': 121,\n",
              " 'B-weight': 122,\n",
              " 'B-weight1': 123,\n",
              " 'B-weight1_not': 124,\n",
              " 'B-weight2': 125,\n",
              " 'B-weight2_not': 126,\n",
              " 'B-weight3': 127,\n",
              " 'B-weight3_not': 128,\n",
              " 'B-weight_not': 129,\n",
              " 'B-weightless': 130,\n",
              " 'B-weightless_not': 131,\n",
              " 'B-weightmore': 132,\n",
              " 'B-weightmore_not': 133,\n",
              " 'I-5G_yes': 134,\n",
              " 'I-5G_yes_not': 135,\n",
              " 'I-RAM1': 136,\n",
              " 'I-RAM1_not': 137,\n",
              " 'I-RAM2': 138,\n",
              " 'I-RAM2_not': 139,\n",
              " 'I-RAM3': 140,\n",
              " 'I-batteryC1': 141,\n",
              " 'I-batteryC1_not': 142,\n",
              " 'I-batteryC2': 143,\n",
              " 'I-batteryC2_not': 144,\n",
              " 'I-batteryC3': 145,\n",
              " 'I-batteryC3_not': 146,\n",
              " 'I-brand1': 147,\n",
              " 'I-brand1_not': 148,\n",
              " 'I-color': 149,\n",
              " 'I-color2': 150,\n",
              " 'I-color2_not': 151,\n",
              " 'I-color_not': 152,\n",
              " 'I-fastCharge_yes': 153,\n",
              " 'I-fastCharge_yes_not': 154,\n",
              " 'I-intermemory1': 155,\n",
              " 'I-intermemory1_not': 156,\n",
              " 'I-intermemory2': 157,\n",
              " 'I-intermemory2_not': 158,\n",
              " 'I-intermemory3': 159,\n",
              " 'I-maincamera1': 160,\n",
              " 'I-maincamera1_not': 161,\n",
              " 'I-maincamera2': 162,\n",
              " 'I-maincamera3': 163,\n",
              " 'I-maincamera3_not': 164,\n",
              " 'I-memorycard_yes': 165,\n",
              " 'I-memorycard_yes_not': 166,\n",
              " 'I-price': 167,\n",
              " 'I-price1': 168,\n",
              " 'I-price1_not': 169,\n",
              " 'I-price2': 170,\n",
              " 'I-price2_not': 171,\n",
              " 'I-price3': 172,\n",
              " 'I-price3_not': 173,\n",
              " 'I-price_not': 174,\n",
              " 'I-priceless': 175,\n",
              " 'I-priceless_not': 176,\n",
              " 'I-pricemore': 177,\n",
              " 'I-pricemore_not': 178,\n",
              " 'I-selficamera1': 179,\n",
              " 'I-selficamera1_not': 180,\n",
              " 'I-selficamera2': 181,\n",
              " 'I-selficamera3': 182,\n",
              " 'I-selficamera3_not': 183,\n",
              " 'I-weight1': 184,\n",
              " 'O': 185,\n",
              " 'PAD': 186}"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tag2id"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R7JomU3LYUmL"
      },
      "source": [
        "part 3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Ey5hBN5Ye32"
      },
      "source": [
        "## **1 sentence - GRU**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LzjhYq_5YXXk"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import psutil\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "import json\n",
        "import pickle\n",
        "import numpy as np\n",
        "\n",
        "def monitor_memory():\n",
        "    memory_usage = psutil.virtual_memory().used / (1024 ** 3)\n",
        "    return memory_usage\n",
        "\n",
        "def predict_gru_sentence(sentence):\n",
        "\n",
        "    # Preprocess the input sentence\n",
        "    sequence = tokenizer.texts_to_sequences([sentence])\n",
        "    padded_sequence = pad_sequences(sequence, maxlen=max_len_sentences, padding='post')\n",
        "\n",
        "    prediction = gru_model.predict(padded_sequence)\n",
        "\n",
        "    predicted_tags = [np.argmax(p) for p in prediction[0]]\n",
        "    predicted_tags = [list(tag_encoder.keys())[list(tag_encoder.values()).index(tag)] for tag in predicted_tags]\n",
        "\n",
        "\n",
        "    return predicted_tags[:len(sentence.split())]\n",
        "\n",
        "\n",
        "##############################\n",
        "ram_before = monitor_memory()\n",
        "##############################\n",
        "\n",
        "# load model\n",
        "gru_model = load_model('gru_bio_tagger_6.h5')\n",
        "\n",
        "# load tokenizer\n",
        "with open('bigru_tokenizer.json', 'r') as f:\n",
        "    tokenizer_config = json.load(f)\n",
        "\n",
        "tokenizer = Tokenizer() # Create a new Tokenizer object\n",
        "\n",
        "tokenizer.word_index = tokenizer_config['word_index'] # Restore tokenizer's attributes\n",
        "tokenizer.word_docs = tokenizer_config['word_docs']\n",
        "tokenizer.index_docs = tokenizer_config['index_docs']\n",
        "\n",
        "# Load the tag encoder from the file\n",
        "with open('tag_encoder.pkl', 'rb') as f:\n",
        "    tag_encoder = pickle.load(f)\n",
        "\n",
        "max_len_sentences = 43\n",
        "\n",
        "sentence = \"من یک گوشی با صفحه نمایش کوچکتر از 4 می خواهم\"\n",
        "\n",
        "##############################\n",
        "start_time = time.time()\n",
        "##############################\n",
        "\n",
        "predicted_tags = predict_gru_sentence(sentence)\n",
        "\n",
        "##############################\n",
        "end_time = time.time()\n",
        "ram_after = monitor_memory()\n",
        "##############################\n",
        "total_time = end_time - start_time\n",
        "ram_usage = ram_after - ram_before\n",
        "##############################\n",
        "\n",
        "print(f\"Sentence: {sentence}\")\n",
        "print(f\"Predicted Tags: {predicted_tags}\")\n",
        "print(f\"Time Taken: {total_time:.4f} seconds\")\n",
        "print(f\"RAM Usage: {ram_usage:.2f} GB\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vp9KzPfQd2gg"
      },
      "source": [
        "## **20% - GRU**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZYAgpNGUd4fF"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import psutil\n",
        "import pandas as pd\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "import json\n",
        "import pickle\n",
        "import numpy as np\n",
        "\n",
        "def monitor_memory():\n",
        "    memory_usage = psutil.virtual_memory().used / (1024 ** 3)\n",
        "    return memory_usage\n",
        "\n",
        "def predict_gru_dataset(sentences):\n",
        "\n",
        "    predictions = []\n",
        "    for sentence in sentences:\n",
        "      sequence = tokenizer.texts_to_sequences([sentence])\n",
        "      padded_sequence = pad_sequences(sequence, maxlen=max_len_sentences, padding='post')\n",
        "      prediction = gru_model.predict(padded_sequence)\n",
        "      predicted_tags = [np.argmax(p) for p in prediction[0]]\n",
        "      predicted_tags = [list(tag_encoder.keys())[list(tag_encoder.values()).index(tag)] for tag in predicted_tags]\n",
        "      predictions.append((sentence, predicted_tags[:len(sentence.split())]))\n",
        "    return predictions\n",
        "\n",
        "\n",
        "\n",
        "##############################\n",
        "ram_before = monitor_memory()\n",
        "##############################\n",
        "\n",
        "# load model\n",
        "gru_model = load_model('gru_bio_tagger_6.h5')\n",
        "\n",
        "# load tokenizer\n",
        "with open('bigru_tokenizer.json', 'r') as f:\n",
        "    tokenizer_config = json.load(f)\n",
        "\n",
        "tokenizer = Tokenizer() # Create a new Tokenizer object\n",
        "\n",
        "tokenizer.word_index = tokenizer_config['word_index'] # Restore tokenizer's attributes\n",
        "tokenizer.word_docs = tokenizer_config['word_docs']\n",
        "tokenizer.index_docs = tokenizer_config['index_docs']\n",
        "\n",
        "# Load the tag encoder from the file\n",
        "with open('tag_encoder.pkl', 'rb') as f:\n",
        "    tag_encoder = pickle.load(f)\n",
        "\n",
        "max_len_sentences = 43\n",
        "\n",
        "# Load 20% of the dataset\n",
        "df = pd.read_csv('dataset2_2.csv', delimiter='\\t', header=None, names=['Sentence', 'Tags', 'Intent'])\n",
        "sample_sentences = df['Sentence'].sample(frac=0.05).values\n",
        "len_sample = len(sample_sentences)\n",
        "\n",
        "##############################\n",
        "start_time = time.time()\n",
        "##############################\n",
        "\n",
        "predictions = predict_gru_dataset(sample_sentences)\n",
        "\n",
        "##############################\n",
        "end_time = time.time()\n",
        "ram_after = monitor_memory()\n",
        "##############################\n",
        "total_time = end_time - start_time\n",
        "ram_usage = ram_after - ram_before\n",
        "time_per_sentence = total_time / len_sample\n",
        "##############################\n",
        "\n",
        "print(f\"Time Taken for 5% of the Dataset: {total_time:.4f} seconds\")\n",
        "print(f\"Time per Sentence: {time_per_sentence:.4f} seconds\")\n",
        "print(f\"RAM Usage: {ram_usage:.2f} GB\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ff-fm8urfn6e"
      },
      "source": [
        "## **1 sentence - parsbert**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NpBWtT-KfuQB"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import psutil\n",
        "from transformers import BertTokenizer, TFBertForTokenClassification\n",
        "import tensorflow as tf\n",
        "import json\n",
        "import pickle\n",
        "\n",
        "def monitor_memory():\n",
        "    memory_usage = psutil.virtual_memory().used / (1024 ** 3)\n",
        "    return memory_usage\n",
        "\n",
        "def predict_parsbert_sentence(sentence):\n",
        "\n",
        "    # Preprocess the input sentence\n",
        "    inputs = tokenizer(sentence, return_tensors=\"tf\", padding=True, truncation=True, max_length=128)\n",
        "    outputs = model(inputs)\n",
        "\n",
        "    logits = outputs.logits\n",
        "    predicted_ids = tf.argmax(logits, axis=-1).numpy().flatten()\n",
        "\n",
        "    # Convert ids to tags\n",
        "    id2tag = {idx: tag for tag, idx in tag2id.items()}\n",
        "    predicted_tags = [id2tag.get(id, 'OOV') for id in predicted_ids]\n",
        "\n",
        "    return predicted_tags\n",
        "\n",
        "\n",
        "##############################\n",
        "ram_before = monitor_memory()\n",
        "##############################\n",
        "\n",
        "# Load tokenizer and model\n",
        "tokenizer = BertTokenizer.from_pretrained(\"ParsBERT_BIO_Tagging_Tokenizer\")\n",
        "model = TFBertForTokenClassification.from_pretrained(\"ParsBERT_BIO_Tagging_Model\")\n",
        "\n",
        "# Load the tag encoder from the file\n",
        "with open('tag_encoder.pkl', 'rb') as f:\n",
        "    tag2id = pickle.load(f)\n",
        "\n",
        "sentence = \"من یک گوشی غیر آیفون و همچنین رم اش با رمی برابر با 3 گیگ می خواهم\"\n",
        "\n",
        "##############################\n",
        "start_time = time.time()\n",
        "##############################\n",
        "\n",
        "predicted_tags = predict_parsbert_sentence(sentence)\n",
        "\n",
        "##############################\n",
        "end_time = time.time()\n",
        "ram_after = monitor_memory()\n",
        "##############################\n",
        "total_time = end_time - start_time\n",
        "ram_usage = ram_after - ram_before\n",
        "##############################\n",
        "\n",
        "print(f\"Predicted Tags: {predicted_tags}\")\n",
        "print(f\"Time Taken: {total_time:.4f} seconds\")\n",
        "print(f\"RAM Usage: {ram_usage:.2f} GB\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_SoiHUgFfu5W"
      },
      "source": [
        "## **20% - parsbert**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "krAs7c7ufzBk"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import psutil\n",
        "from transformers import BertTokenizer, TFBertForTokenClassification\n",
        "import tensorflow as tf\n",
        "import json\n",
        "import pickle\n",
        "import pandas as pd\n",
        "\n",
        "def monitor_memory():\n",
        "    memory_usage = psutil.virtual_memory().used / (1024 ** 3)\n",
        "    return memory_usage\n",
        "\n",
        "def predict_parsbert_dataset(sentences):\n",
        "\n",
        "    predictions = []\n",
        "    for sentence in sentences:\n",
        "        inputs = tokenizer(sentence, return_tensors=\"tf\", padding=True, truncation=True, max_length=128)\n",
        "        outputs = model(inputs)\n",
        "        logits = outputs.logits\n",
        "        predicted_ids = tf.argmax(logits, axis=-1).numpy().flatten()\n",
        "        id2tag = {idx: tag for tag, idx in tag2id.items()}\n",
        "        predicted_tags = [id2tag.get(id, 'OOV') for id in predicted_ids]\n",
        "        predictions.append(predicted_tags)\n",
        "\n",
        "    return predictions\n",
        "\n",
        "\n",
        "##############################\n",
        "ram_before = monitor_memory()\n",
        "##############################\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained(\"ParsBERT_BIO_Tagging_Tokenizer\")\n",
        "model = TFBertForTokenClassification.from_pretrained(\"ParsBERT_BIO_Tagging_Model\")\n",
        "\n",
        "# Load 5% of the dataset\n",
        "df = pd.read_csv('dataset2_2.csv', delimiter='\\t', header=None, names=['Sentence', 'Tags', 'Intent'])\n",
        "sample_sentences = df['Sentence'].sample(frac=0.05).values\n",
        "len_sample = len(sample_sentences)\n",
        "\n",
        "with open('tag_encoder.pkl', 'rb') as f:\n",
        "    tag2id = pickle.load(f)\n",
        "\n",
        "##############################\n",
        "start_time = time.time()\n",
        "##############################\n",
        "\n",
        "predictions = predict_parsbert_dataset(sample_sentences)\n",
        "\n",
        "##############################\n",
        "end_time = time.time()\n",
        "ram_after = monitor_memory()\n",
        "##############################\n",
        "total_time = end_time - start_time\n",
        "ram_usage = ram_after - ram_before\n",
        "time_per_sentence = total_time / len_sample\n",
        "##############################\n",
        "\n",
        "print(f\"Time Taken for 5% of the Dataset: {total_time:.4f} seconds\")\n",
        "print(f\"Time per Sentence: {time_per_sentence:.4f} seconds\")\n",
        "print(f\"RAM Usage: {ram_usage:.2f} GB\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv('dataset2_2.csv', delimiter='\\t', header=None, names=['Sentence', 'Tags', 'Intent'])\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 803
        },
        "id": "EItL5OAZVKmo",
        "outputId": "7db9ce04-6295-4f63-c2bc-4b643a32dbaa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                Sentence  \\\n",
              "0          من یک گوشی با صفحه نمایش کوچکتر از 4 می خواهم   \n",
              "1               من یک گوشی با برندی به جز هوآوی می خواهم   \n",
              "2      من یک گوشی با حداکثر کیفیت دوربین 12 مگاپیکسل ...   \n",
              "3          من یک گوشی دوربینش حداقل برابر با 25 می خواهم   \n",
              "4      من یک گوشی غیر آیفون و همچنین رم اش با رمی برا...   \n",
              "...                                                  ...   \n",
              "13486                دوست ندارم با قابلیت شارژ سریع باشد   \n",
              "13487                          دوست ندارم دارای قلم باشد   \n",
              "13488                        دوست ندارم با ظاهر شیک باشد   \n",
              "13489                 دوست ندارم دارای پردازنده خوب باشد   \n",
              "13490                  دوست ندارم مال کشور سنگاپوری باشد   \n",
              "\n",
              "                                                    Tags          Intent  \n",
              "0                  O O O O O O O O B-displaySizeless O O  suggest_mobile  \n",
              "1                          O O O O O O O B-brand_not O O  suggest_mobile  \n",
              "2                   O O O O O O O B-maincameraless O O O  suggest_mobile  \n",
              "3                     O O O O O O O B-maincameramore O O  suggest_mobile  \n",
              "4        O O O O B-brand_not O O O O O O O O B-RAM O O O  suggest_mobile  \n",
              "...                                                  ...             ...  \n",
              "13486  O O O O B-fastCharge_yes_not I-fastCharge_yes_...  suggest_mobile  \n",
              "13487                              O O O B-pen_yes_not O  suggest_mobile  \n",
              "13488                   O O O O B-appearanceScore1_not O  suggest_mobile  \n",
              "13489                      O O O O B-chipsetScore1_not O  suggest_mobile  \n",
              "13490                             O O O O B-madeIn_not O  suggest_mobile  \n",
              "\n",
              "[13491 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4709d230-9691-446b-9008-fa4925d6b34c\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentence</th>\n",
              "      <th>Tags</th>\n",
              "      <th>Intent</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>من یک گوشی با صفحه نمایش کوچکتر از 4 می خواهم</td>\n",
              "      <td>O O O O O O O O B-displaySizeless O O</td>\n",
              "      <td>suggest_mobile</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>من یک گوشی با برندی به جز هوآوی می خواهم</td>\n",
              "      <td>O O O O O O O B-brand_not O O</td>\n",
              "      <td>suggest_mobile</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>من یک گوشی با حداکثر کیفیت دوربین 12 مگاپیکسل ...</td>\n",
              "      <td>O O O O O O O B-maincameraless O O O</td>\n",
              "      <td>suggest_mobile</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>من یک گوشی دوربینش حداقل برابر با 25 می خواهم</td>\n",
              "      <td>O O O O O O O B-maincameramore O O</td>\n",
              "      <td>suggest_mobile</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>من یک گوشی غیر آیفون و همچنین رم اش با رمی برا...</td>\n",
              "      <td>O O O O B-brand_not O O O O O O O O B-RAM O O O</td>\n",
              "      <td>suggest_mobile</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13486</th>\n",
              "      <td>دوست ندارم با قابلیت شارژ سریع باشد</td>\n",
              "      <td>O O O O B-fastCharge_yes_not I-fastCharge_yes_...</td>\n",
              "      <td>suggest_mobile</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13487</th>\n",
              "      <td>دوست ندارم دارای قلم باشد</td>\n",
              "      <td>O O O B-pen_yes_not O</td>\n",
              "      <td>suggest_mobile</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13488</th>\n",
              "      <td>دوست ندارم با ظاهر شیک باشد</td>\n",
              "      <td>O O O O B-appearanceScore1_not O</td>\n",
              "      <td>suggest_mobile</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13489</th>\n",
              "      <td>دوست ندارم دارای پردازنده خوب باشد</td>\n",
              "      <td>O O O O B-chipsetScore1_not O</td>\n",
              "      <td>suggest_mobile</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13490</th>\n",
              "      <td>دوست ندارم مال کشور سنگاپوری باشد</td>\n",
              "      <td>O O O O B-madeIn_not O</td>\n",
              "      <td>suggest_mobile</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>13491 rows × 3 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4709d230-9691-446b-9008-fa4925d6b34c')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-4709d230-9691-446b-9008-fa4925d6b34c button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-4709d230-9691-446b-9008-fa4925d6b34c');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-889efce3-7167-497c-adc5-12b431c7e200\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-889efce3-7167-497c-adc5-12b431c7e200')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-889efce3-7167-497c-adc5-12b431c7e200 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_01192779-9b60-4b5a-af7a-afbf71dfaef9\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_01192779-9b60-4b5a-af7a-afbf71dfaef9 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 13491,\n  \"fields\": [\n    {\n      \"column\": \"Sentence\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 13414,\n        \"samples\": [\n          \"\\u0686\\u0647 \\u06af\\u0648\\u0634\\u06cc \\u0647\\u0627\\u06cc\\u06cc \\u063a\\u06cc\\u0631 \\u0627\\u0646\\u062f\\u0631\\u0648\\u06cc\\u062f \\u0645\\u0648\\u062c\\u0648\\u062f \\u0627\\u0633\\u062a \\u06a9\\u0647 \\u0627\\u0631\\u0632\\u0634 \\u062e\\u0631\\u06cc\\u062f \\u062f\\u0627\\u0634\\u062a\\u0647 \\u0628\\u0627\\u0634\\u0646\\u062f \\u061f\",\n          \"\\u0628\\u0647 \\u062f\\u0646\\u0628\\u0627\\u0644 \\u06af\\u0648\\u0634\\u06cc \\u062f\\u0627\\u0631\\u0627\\u06cc \\u067e\\u0631\\u062f\\u0627\\u0632\\u0646\\u062f\\u0647 \\u0628\\u062f \\u0648 \\u0628\\u0627 \\u062d\\u0627\\u0641\\u0638\\u0647 \\u062e\\u06cc\\u0644\\u06cc \\u0628\\u062f \\u0647\\u0633\\u062a\\u0645\",\n          \"\\u0628\\u0647\\u062a\\u0631\\u06cc\\u0646 \\u06af\\u0648\\u0634\\u06cc \\u0628\\u0631\\u0627\\u06cc \\u0645\\u0646 \\u0628\\u0627\\u06cc\\u062f \\u062f\\u0627\\u0631\\u0627\\u06cc \\u067e\\u0631\\u062f\\u0627\\u0632\\u0646\\u062f\\u0647 \\u0636\\u0639\\u06cc\\u0641 \\u0648 \\u0628\\u0627 \\u062d\\u0627\\u0641\\u0638\\u0647 \\u0646\\u0627\\u0645\\u0646\\u0627\\u0633\\u0628 \\u0628\\u0627\\u0634\\u062f\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Tags\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 12688,\n        \"samples\": [\n          \"O O O O O O O B-pricemore I-pricemore O O O O B-batteryC O O O O O\",\n          \"O O O O O B-madeIn O O O O O O B-brand_not O O O O O O O B-maincamera O O\",\n          \"O O O O O O O B-memorycard_yes I-memorycard_yes O O O O O\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Intent\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"suggest_mobile\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ohnh2V_JVLa0"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "K2BIUo1obI2S",
        "A4Am7dtWbDdg",
        "4Ey5hBN5Ye32",
        "Vp9KzPfQd2gg",
        "ff-fm8urfn6e",
        "_SoiHUgFfu5W"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}